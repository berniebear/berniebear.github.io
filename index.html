<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Bernie Website</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <!-- Custom styles for this template -->
  <link href="css/resume.min.css" rel="stylesheet">

</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">Po-Yao Huang</span>
      <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile.jpg" alt="">
      </span>
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#work">Work Experience</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#education">Education</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#publication">Publication</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#honors">Honors</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="https://github.com/berniebear/berniebear.github.io/cv/CV_Bernie_2022b.pdf">CV</a>
        </li>  
      </ul>
    </div>
  </nav>

  <div class="container-fluid p-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="about">
      <div class="w-100">
        <h1 class="mb-0">Po-Yao (Bernie)
          <span class="text-primary">Huang</span>
        </h1>
        <div class="subheading mb-5">School of Computer Science, Carnegie Mellon University.
          <a href="mailto:poyaoh@cs.cmu.edu">poyaoh@cs.cmu.edu</a>
        </div>
	<p class="lead mb-5">Greetings! I am Po-Yao (Bernie) Huang. I am a research scientist at Facebook AI Research (FAIR). I obtained my Ph.D. degree in the <a href="http://www.lti.cs.cmu.edu" target="_blank">Language Technologies Institute (LTI)</a> of <a href="http://www.cs.cmu.edu" target="_blank">School of Computer Science (SCS)</a> at <a href="http://www.cmu.edu" target="_blank">Carnegie Mellon University (CMU)</a> in 2021. My research interest is multimodal machine learning. I am particularly interested in bridging computer vision and natural language processing for the tasks of multimodal machine translation, cross-modal search and retrieval, and large-scale multimodal data mining and analysis.
        </p>
        <div class="social-icons">
          <a href="https://scholar.google.com/citations?user=E8K25LIAAAAJ&hl=en">
            <i class="fa fa-google"></i>
          </a>
        </div>
      </div>
    </section>
    <hr class="m-0">
    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="work">
      <div class="w-100">
        <h2 class="mb-5">Work Experience</h2>
        <div class="resume-item d-flex flex-column justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-2">Facebook</h3>
            <div class="mb-2">
              <span class="text-primary-left">Senior Research Scientist (FAIR Labs)</span>
              <span class="text-primary-right">Aug 2022 - present</span>
            </div>
            <h3 class="mb-2">Facebook</h3>
            <div class="mb-2">
              <span class="text-primary-left">Research Scientist (FAIR Labs)</span>
              <span class="text-primary-right">Aug 2021 - Aug 2022</span>
            </div>
            <div class="mb-2">
              <span class="text-primary-left">Research Intern</span>
              <span class="text-primary-right">May 2020 - May 2021</span>
            </div>
          </div>
        </div>
        <div class="resume-item d-flex flex-column justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-2">MicroSoft</h3>
            <div class="mb-2">
              <span class="text-primary-left">Research Intern (Microsoft Research)</span>
              <span class="text-primary-right">Jun 2017 - Aug 2017</span>
            </div>
          </div>
        </div>
        <div class="resume-item d-flex flex-column justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-2">MediaTek</h3>
            <div class="mb-2">
              <span class="text-primary-left">Senior Software Engineer</span>
              <span class="text-primary-right">Jun 2012 - Jun 2014</span>
            </div>
            <div class="mb-2">
              <span class="text-primary-left">Software Engineer</span>
              <span class="text-primary-right">Sep 2010 - May 2012</span>
            </div>
          </div>
        </div>
      </div>
    </section>

    <hr class="m-0">
    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="education">
      <div class="w-100">
        <h2 class="mb-5">Education</h2>
        <div class="resume-item d-flex flex-column justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-2">Carnegie Mellon University</h3>
            <div class="mb-2">
              <span class="text-primary-left">Ph.D. in Computer Science - Language and Information Technologies</span>
              <span class="text-primary-right">Aug 2016 - Jul 2021</span>
              <p>GPA: 4.33/4.33</p>
              <span class="text-primary-left">M.S. in Computer Science - Language Technologies</span>
              <span class="text-primary-right">Aug 2014 - Jul 2016</span>
              <p>GPA: 4.21/4.33</p>
            </div>
          </div>
        </div>
        <div class="resume-item d-flex flex-column justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-2">National Taiwan University</h3>
            <div class="mb-2">
              <span class="text-primary-left">M.S. in Computer Engineering</span>
              <span class="text-primary-right">Aug 2007 - Jul 2009</span>
              <p>GPA: 4.00/4.00</p>
              <span class="text-primary-left">B.S. in Electrical Engineering</span>
              <span class="text-primary-right">Sep 2003 - Jul 2007</span>
              <p>GPA: 3.78/4.00</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    
    <hr class="m-0">
    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="publication">
      <div class="w-100">
          <h2 class="mb-5">Publication</h2>

<ul style="font-family: Arial;">
  <li>
    <a href="https://arxiv.org/pdf/2306.00989.pdf">Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles</a><br>
    <small>Chaitanya Ryali, Yuan-Ting Hu, Daniel Bolya, Chen Wei, Haoqi Fan, Po-Yao Huang, Vaibhav Aggarwal, Arkabandhu Chowdhury, Omid Poursaeed, Judy Hoffman, Jitendra Malik, Yanghao Li, Christoph Feichtenhofer</small><br>
    <small><span style="font-style: italic;">ICML</span>, 2023</small>.
  </li>
</ul>
<ul style="font-family: Arial;">
  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_STMT_A_Spatial-Temporal_Mesh_Transformer_for_MoCap-Based_Action_Recognition_CVPR_2023_paper.pdf">STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition</a><br>
    <small>Xiaoyu Zhu, Po-Yao Huang, Junwei Liang, Alexander G Hauptmann</small><br>
    <small><span style="font-style: italic;">CVPR</span>, 2023</small>.
  </li>
</ul>
<ul style="font-family: Arial;">
  <li>
    <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/b89d5e209990b19e33b418e14f323998-Paper-Conference.pdf">Masked autoencoders that listen</a><br>
    <small>Po-Yao Huang, Hu Xu, Juncheng Li, Alexei Baevski, Michael Auli, Wojciech Galuba, Florian Metze, Christoph Feichtenhofer</small><br>
    <small><span style="font-style: italic;">NeurIPS</span>, 2022</small>.
  </li>
</ul>


</ul>
<ul style="font-family: Arial;">
  <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/9792411">Video pivoting unsupervised multi-modal machine translation</a><br>
    <small>Mingjie Li, Po-Yao Huang, Xiaojun Chang, Junjie Hu, Yi Yang, Alex Hauptmann</small><br>
    <small><span style="font-style: italic;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>, June 2022</small>.
  </li>
</ul>

</ul>
<ul style="font-family: Arial;">
  <li>
    <a href="https://arxiv.org/pdf/2203.12122">On adversarial robustness of large-scale audio visual learning (Best student paper)</a><br>
    <small>Juncheng B Li, Shuhui Qu, Xinjian Li, Po-Yao Bernie Huang, Florian Metze</small><br>
    <small><span style="font-style: italic;">ICASSP</span>, 2022</small>.
  </li>
</ul>
<ul style="font-family: Arial;">
  <li>
    <a href="https://arxiv.org/pdf/2109.14084">Videoclip: Contrastive pre-training for zero-shot video-text understanding</a>
    <br>
    <small>Hu Xu, Gargi Ghosh, Po-Yao Huang, Dmytro Okhonko, Armen Aghajanyan, Florian Metze, Luke Zettlemoyer, Christoph Feichtenhofer</small><br>
    <small><span style="font-style: italic;">EMNLP</span>, 2021</small>.
  </li>
</ul>
<ul style="font-family: Arial;">
  <li>
    <a href="https://drive.google.com/file/d/14_sMLL6jquMMk0NNZVN_TUln4NnKb3HR/view?usp=sharing">Towards Multilingual Vision-Language Models</a>
    <br>
    <small>Po-Yao Huang</small><br>
    <small><span style="font-style: italic;">Ph.D. Thesis</span>, 2021.</small> [<a href="https://drive.google.com/file/d/1wQzzoc4mOvrky-oF_l_FakwxPOunHiIF/view?usp=sharing">slides</a>]

  </li>
</ul>
<ul style="font-family: Arial;">
  <li>
    <a href="https://arxiv.org/pdf/2105.09996.pdf">VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding</a><br>
    <small>Hu Xu, Gargi Ghosh, Po-Yao Huang, Prahal Arora, Masoumeh Aminzadeh, Christoph Feichtenhofer, Florian Metze, Luke Zettlemoyer</small><br>
    <small><span style="font-style: italic;">Findings of the 59th Annual Meeting of the Association for Computational Linguistics (ACL-Findings)</span>, 2021</small>.
  </li>
</ul>
<ul style="font-family: Arial;">
  <li>
    <a href="https://arxiv.org/pdf/2103.08849.pdf">Multilingual Multimodal Pre-training for Zero-Shot Cross-Lingual Transfer of Vision-Language Models</a><br>
    <small>Po-Yao Huang*, Mandela Patrick*, Junjie Hu, Graham Neubig, Florian Metze, Alexander Hauptmann</small><br>
    <small><span style="font-style: italic;"> The 2021 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</span>, 2021</small>.
  </li>
</ul>
<ul style="font-family: Arial;">
  <li>
    <a href="https://arxiv.org/pdf/2010.02824.pdf">Support-set bottlenecks for video-text representation learning</a><br>
    <small>Mandela Patrick*, Po-Yao Huang*, Yuki Asano*, Florian Metze, Alexander Hauptmann, João Henriques, Andrea Vedaldi</small><br>
    <small><span style="font-style: italic;">International Conference on Learning Representations (ICLR)</span>, 2021</small>.
  </li>
</ul>

<ul style="font-family: Arial;">
  <li>
    <a href="https://www.aclweb.org/anthology/2020.acl-main.731.pdf">Unsupervised Multimodal Neural Machine Translation with Pseudo Visual Pivoting</a><br>
    <small>Po-Yao Huang, Junjie Hu, Xiaojun Chang, Alexander Hauptmann</small><br>
    <small><span style="font-style: italic;">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)</span>, 2020</small>.
  </li>
</ul>

<ul style="font-family: Arial;">
  <li>
    <a href="https://dl.acm.org/doi/pdf/10.1145/3372278.3390674">Forward and Backward Multimodal NMT for Improved Monolingual and Multilingual Cross-Modal Retrieval</a><br>
    <small>Po-Yao Huang, Xiaojun Chang, Alexander Hauptmann, Eduard Hovy</small><br>
    <small><span style="font-style: italic;">Proceedings of the 2019 on ACM International Conference on Multimedia Retrieval (ACM ICMR)</span>, 2020</small>.
  </li>
</ul>


<ul style="font-family: Arial;">
  <li>
    <a href="https://www.nature.com/articles/s41598-020-57866-2">Structural Analysis and Optimization of Convolutional Neural Networks with a Small Sample Size</a><br>
    <small>Rhett N D’souza, Po-Yao Huang, Fang-Cheng Yeh</small><br>
    <small><span style="font-style: italic;">Scientific Reports</span>, Jan 2020</small>.
  </li>
</ul>



<ul style="font-family: Arial;">
  <li>
    <a href="https://www.aclweb.org/anthology/D19-1154.pdf">Multi-Head Attention with Diversity for Learning Grounded Multilingual Multimodal Representations</a><br>
    <small>Po-Yao Huang, Xiaojun Chang, Alexander Hauptmann</small><br>
    <small><span style="font-style: italic;">Proceedings of Empirical Methods in Natural Language Processing (EMNLP)</span>, 2019</small>.
  </li>
</ul>



<ul style="font-family: Arial;">
  <li>
    <a href="http://www.cs.cmu.edu/~poyaoh/data/ann.pdf">Annotation Efficient Cross-Modal Retrieval with Adversarial Attentive Alignment.</a><br>
    <small>Po-Yao Huang, Guoliang Kang, Wenhe Liu, Xiaojun Chang, Alexander G Hauptmann</small><br>
    <small><span style="font-style: italic;">Proceedings of the 27th ACM International Conference on Multimedia (ACM MM)</span>, 2019</small>.
  </li>
</ul>



<ul style="font-family: Arial;">
  <li>
    <a href="http://www.cs.cmu.edu/~poyaoh/data/oan.pdf">Improving What Cross-Modal Retrieval Models Learn through Object-Oriented Inter- and Intra-Modal Attention Networks</a><br>
    <small>Po-Yao Huang, Vaibhav, Xiaojun Chang, Alexander Hauptmann</small><br>
    <small><span style="font-style: italic;">Proceedings of the 2019 on ACM International Conference on Multimedia Retrieval (ACM ICMR)</span>, 2019</small>.
  </li>
</ul>


<ul style="font-family: Arial;">
  <li>
    <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Xiaojun_Chang_RCAA_Relational_Context-Aware_ECCV_2018_paper.pdf">RCAA: Relational Context-Aware Agents for Person Search</a><br>
    <small>Xiaojun Chang, Po-Yao Huang, Yi-Dong Shen, Xiaodan Liang, Yi Yang, Alexander Hauptmann</small><br>
    <small><span style="font-style: italic;">Proceedings of the European Conference on Computer Vision (ECCV)</span>, 2018</small>.
  </li>
</ul>



<ul style="font-family: Arial;">
  <li>
    <a href="https://dl.acm.org/citation.cfm?id=3206025.3206079">Multimodal Filtering of Social Media for Temporal Monitoring and Event Analysis</a><br>
    <small>Po-Yao Huang, Junwei Liang, Jean-Baptiste Lamare, Alexander Hauptmann</small><br>
    <small><span style="font-style: italic;">Proceedings of the 2018 on ACM International Conference on Multimedia Retrieval (ACM ICMR)</span>, 2018</small>.
  </li>
</ul>



<ul style="font-family: Arial;">
  <li>
    <a href="https://arxiv.org/pdf/1707.01408">Video Representation Learning and Latent Concept Mining for Large-scale Multi-label Video Classification</a><br>
    <small>Po-Yao Huang, Ye Yuan, Zhenzhong Lan, Lu Jiang, Alexander Hauptmann  </small><br>
    <small><span style="font-style: italic;"> YouTube 8M Workshop at IEEE Conference on Computer Vision and Pattern Recognition (YT8M@CVPR)</span>, 2017</small>.
  </li>
</ul>


<ul style="font-family: Arial;">
  <li>
    <a href="http://www.cs.cmu.edu/~poyaoh/data/ICASSP_2017.pdf">Synchronization for Multi-Perspective Videos in the Wild</a><br>
    <small>Junwei Liang, Po-Yao Huang, Jia Chen, Alexander Hauptmann  </small><br>
    <small><span style="font-style: italic;"> The 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, 2017</small>.
  </li>
</ul>

<ul style="font-family: Arial;">
  <li>
    <a href="http://www.cs.cmu.edu/~poyaoh/data/aaai17_ever.pdf">An Event Reconstruction Tool for Conflict Monitoring in Social Media</a><br>
    <small>Junwei Liang, Desai Fan, Han Lu, Po-Yao Huang, Jia Chen, Lu Jiang and Alexander Hauptmann </small><br>
    <small><span style="font-style: italic;">The Thirty-First AAAI Conference on Artificial Intelligence (AAAI)</span>, 2017</small>.
  </li>
</ul>


<ul style="font-family: Arial;">
  <li>
    <a href="http://www.statmt.org/wmt16/pdf/W16-2360.pdf">Attention-based Multimodal Neural Machine Translation</a><br>
    <small>Po-Yao Huang, Frederick Liu, Sz-Rung Shiang, Jean Oh, Chris Dyer</small><br>
    <small><span style="font-style: italic;"> ACL 2016 First Conference on Machine Translation (WMT16)</span>, 2016</small>.
  </li>
</ul>



<ul style="font-family: Arial;">
  <li>
    <a href="http://www.cs.cmu.edu/~poyaoh/data/acl15entity.pdf">Entity Hierarchy Embedding</a><br>
    <small>Zhi-Ting Hu, Po-Yao Huang, Yuntian Deng, Yingkai Gao, and Eric Xing [<a href="http://www.cs.cmu.edu/~poyaoh/data/acl15entity_supp.pdf">supp</a>]</small><br>
    <small><span style="font-style: italic;"> The 53rd Annual Meeting of the Association for Computational Linguistics (ACL)</span>, 2015</small>.
  </li>
</ul>

<ul style="font-family: Arial;">
  <li>
    <a href="http://www.cs.cmu.edu/~zhitingh/data/acl15entity.pdf">Cognitive Vertical Handover in Heterogeneous Networks</a><br>
    <small>S.M. Cheng, Po-Yao Huang</small><br> 
    <small><span style="font-style: italic;"> The 11th EAI International Conference on Heterogeneous Networking for Quality, Reliability, Security and Robustness (QSHINE)</span>, 2015</small>.
  </li>
</ul>

<ul style="font-family: Arial;">
  <li>
    <a href="http://www.cs.cmu.edu/~zhitingh/data/acl15entity.pdf">A Cognitive CSMA-based Multichannel MAC for Cognitive Radio
Network</a><br>
    <small>Po-Yao Huang and K.C. Chen</small><br>
    <small><span style="font-style: italic;">  Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA-ASC) </span>, 2009</small>.
  </li>
</ul>

      </div>
    </section>



    <hr class="m-0">
    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="honors">
      <div class="w-100">
        <h2 class="mb-3">Awards</h2>
        <ul class="fa-ul mb-0">
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            1st Place in the TREC <a href="http://dcs.gla.ac.uk/~richardm/TREC_IS/">Incident Streams</a> challenge 2019
          </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            1st Place in the TRECVID <a href="https://actev.nist.gov/">ActEV</a> (Activities in Extended Videos) challenge 2019
          </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            2nd Place in the Kinetics-800 Action Recognition challenge in <a href="http://activity-net.org/">ActivityNet</a> 2019
          </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            1st Place in the ActEV challenge in <a href="http://activity-net.org/">ActivityNet</a> 2019
          </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            2nd Place in the TRECVID <a href="https://www-nlpir.nist.gov/projects/tv2019/index.html">Ad-hoc Video Search</a> challenge 2018
          </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            2nd Place in the <a href="https://research.google.com/youtube8m/index.html">Youtube 8M</a> challenge 2017
          </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            Named <a href="http://www.siebelscholars.com/scholars/Po-YaoHuang">Siebel Scholar</a> (Top CS/Business students in top graduate schools worldwide) 2016
          </li>
        </ul>
        <hr>
        <h2 class="mb-3">Scholarship</h2>
        <ul class="fa-ul mb-0">
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
              ACL, ICMR, AAAI, ACM MM, CVPR travel awards/grants, 2015-2019
          </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
              NSF travel awards, 2015-2019
          </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
              CMU Research Fellowship 2014-2019
          </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
              Taiwan's Study Abroad Scholarship, 2016
          </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
              Siebel Scholarship, 2016
          </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
              Din-Jing Memorial Scholarship, 2009
          </li>      
        </ul>
      </div>
    </section>
  </div>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/resume.min.js"></script>

</body>

</html>
